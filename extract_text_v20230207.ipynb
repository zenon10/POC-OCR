{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zMUYVHHUiAbKxoXzte5-biqGJ-kSNJPk",
      "authorship_tag": "ABX9TyNmfBIwxTBnQju1cvX+wRv1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenon10/POC-OCR/blob/main/extract_text_v20230207.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Installations**"
      ],
      "metadata": {
        "id": "fPlE02oDv9Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For pdf\n",
        "! pip install pypdfium2"
      ],
      "metadata": {
        "id": "iiL2tzxOv8iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "#Explicitly for french language\n",
        "! sudo apt-get install tesseract-ocr-fra"
      ],
      "metadata": {
        "id": "7E6Zc4PnOXKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For textract \n",
        "!apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils \\\n",
        "     pstotext tesseract-ocr \\\n",
        "     flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libasound2-dev libpulse-dev\n",
        "!pip install git+https://github.com/deanmalmgren/textract"
      ],
      "metadata": {
        "id": "7L-dCPMev4ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Libraries**"
      ],
      "metadata": {
        "id": "Jg3ia-a75oh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library to work with Operating Syatem\n",
        "import os\n",
        "\n",
        "# Library to create PDF, inspection, manupulation and rendering(turning into images)\n",
        "import pypdfium2 as pdfium\n",
        "\n",
        "# Regex lirary to manipulate string\n",
        "import re\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import textract"
      ],
      "metadata": {
        "id": "Xm-Sy6Kzhm6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image"
      ],
      "metadata": {
        "id": "1PJS1srzOF9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Defining Function**"
      ],
      "metadata": {
        "id": "oq7Zjjp85xvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_img(input1):\n",
        "    \n",
        "    # if not os.path.exists(output_folder_path):\n",
        "    #     os.makedirs(output_folder_path)\n",
        "\n",
        "    input_file_name = os.path.split(input1)[-1].replace('.pdf','')   \n",
        "    print('Extracting text from {}'.format(input_file_name))\n",
        "    \n",
        "    # PdfDocument (supports file path strings, bytes, and byte buffers)\n",
        "    pdf_info = pdfium.PdfDocument(input1)\n",
        "    \n",
        "    # get the number of pages in the document\n",
        "    n_pages = len(pdf_info)\n",
        "    print(n_pages)\n",
        "    \n",
        "    page_indices = [i for i in range(n_pages)]    \n",
        "    renderer = pdf_info.render_to(pdfium.BitmapConv.pil_image, page_indices = page_indices, scale = 300/72)\n",
        "\n",
        "    page_number = 1\n",
        "    output_folder_path = os.path.split(input1)[0]\n",
        "    for images in renderer:\n",
        "#         print(images.show())\n",
        "\n",
        "        images.save(output_folder_path + \"/\" + str(page_number)  + '.jpeg')\n",
        "        page_number +=1"
      ],
      "metadata": {
        "id": "9CKIjLRQTxfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_txt(img_path,language):\n",
        "    \n",
        "    # if not os.path.exists(output_folder_path):\n",
        "    #     os.makedirs(output_folder_path)\n",
        "    \n",
        "    try:\n",
        "        path = glob.glob(img_path + \"/*.jpeg\")\n",
        "        print(path)\n",
        "    except:\n",
        "        print('image not in jpeg')\n",
        "    \n",
        "        \n",
        "    ## Blank string to concatenate all text string outputs from ocr for each image\n",
        "    combined_text = ''\n",
        "\n",
        "    ## Defining output folder to save your text file\n",
        "    output_folder_path = img_path\n",
        "    # print(output_folder_path)\n",
        "    for img in path:\n",
        "        \n",
        "        file_name = os.path.basename(img).replace('.jpeg','')\n",
        "        print(\"File name:\", file_name)\n",
        "        \n",
        "        ## Extracting text from image\n",
        "        text = pytesseract.image_to_string(Image.open(img), lang=language)\n",
        "        \n",
        "        ## Concatenating text-string outputs from each image into one master text-string\n",
        "        combined_text = (\"\\n**\" + file_name + \" **\\n\").join([combined_text, text])\n",
        "        \n",
        "        ## Creating separate text files for each image\n",
        "        # with open(output_folder_path + \"/\" + file_name +'.txt', \"w\",encoding=\"utf8\") as f:\n",
        "        #     f.write(text)\n",
        "        \n",
        "        ## Writing in a pandas dataframe\n",
        "        # df.loc[len(df.index)] = [img, output_folder_path + file_name +'.txt', language]\n",
        "        \n",
        "    ## Open a file with access mode 'a'\n",
        "    file_object2 = open(output_folder_path + \"/\" + 'Combined_text.txt', 'a',encoding=\"utf8\")\n",
        "    file_object2.write(combined_text)\n",
        "    file_object2.close()"
      ],
      "metadata": {
        "id": "F67eGMwyT1oN"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doc_docx_xlsx_to_text(file_path):\n",
        "    text_file = textract.process(file_paths)\n",
        "    with open(os.path.split(file_paths)[0] + '/'+'text.txt', \"w\") as f:\n",
        "        f.write(text_file.decode('utf8', 'strict'))"
      ],
      "metadata": {
        "id": "oz-vC_B0vZ9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "GdvuDqbACvRa"
      },
      "outputs": [],
      "source": [
        "def raw_data_to_text_file(input1, language ='fra'):\n",
        "    '''\n",
        "    This function takes pdf, doc, docx and excel files and extract text file.\n",
        "\n",
        "    Input parameters- \n",
        "        input1 is folder path containing documents.\n",
        "        language of the input document. By default, it is french. eg: 'fra', 'ita', ..\n",
        "    Output-\n",
        "        For pdf files the output will be jpeg files and txt files\n",
        "        For doc, docx and the excel file output will be only txt files.\n",
        "    '''\n",
        "\n",
        "    path = glob.glob(input1)\n",
        "    print(\"List of folders present in input folder: \",path)\n",
        "\n",
        "    for i in path:\n",
        "        try:\n",
        "            file_paths = str(glob.glob(i + '/*')[0])\n",
        "            print(\"Input file path: \",file_paths)\n",
        "        \n",
        "            file_name_extn = os.path.basename(file_paths).split('.')[1]\n",
        "\n",
        "            if file_name_extn == 'pdf':\n",
        "                pdf_to_img(file_paths)\n",
        "                img_to_txt(i,language)\n",
        "\n",
        "            else: ##file_name in ['doc','docx','xlsx']:\n",
        "                text_file = textract.process(file_paths)\n",
        "\n",
        "                with open(os.path.split(file_paths)[0] + '/'+'Combined_text.txt', \"w\") as f:\n",
        "                    f.write(text_file.decode('utf8', 'strict'))\n",
        "        except:\n",
        "            print('***files not found***')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(raw_data_to_text_file)"
      ],
      "metadata": {
        "id": "5azZPD5LyrMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Testing**"
      ],
      "metadata": {
        "id": "pSBNzyWw6QZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_to_text_file('/content/drive/MyDrive/Zenon_POC_OCR/documents/*')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYJNMD6fXeaD",
        "outputId": "a452dd52-86c2-4485-adeb-6a3cc910a525"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of folders present in input folder:  ['/content/drive/MyDrive/Zenon_POC_OCR/documents/f1_doc', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1']\n",
            "Input file path:  /content/drive/MyDrive/Zenon_POC_OCR/documents/f1_doc/f1_doc.doc\n",
            "Input file path:  /content/drive/MyDrive/Zenon_POC_OCR/documents/f1/f1.pdf\n",
            "Extracting text from f1\n",
            "6\n",
            "['/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/1.jpeg', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/2.jpeg', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/3.jpeg', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/4.jpeg', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/5.jpeg', '/content/drive/MyDrive/Zenon_POC_OCR/documents/f1/6.jpeg']\n",
            "File name: 1\n",
            "File name: 2\n",
            "File name: 3\n",
            "File name: 4\n",
            "File name: 5\n",
            "File name: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwNpNq_980R9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}